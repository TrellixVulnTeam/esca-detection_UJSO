{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1031
    },
    "colab_type": "code",
    "id": "1lg4YL2PLPu1",
    "outputId": "b8bea3cd-a7a6-4090-b676-5ee7cc581e8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\n",
      "E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n",
      "W: chmod 0700 of directory /var/lib/apt/lists/partial failed - SetupAPTPartialDirectory (1: Operation not permitted)\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\n",
      "E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9779d4ff2e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt-get update -qq 2>&1 > /dev/null'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt-get -y install -qq google-drive-ocamlfuse fuse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# fusing Google Drive\n",
    "\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PiYKE8HvP5Sb"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kH3VuDYNet7p",
    "outputId": "fab76bc3-95c8-4139-b9f6-89e1627ce070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/esca_hackathon\n"
     ]
    }
   ],
   "source": [
    "cd drive/esca_hackathon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "94LKvwzd8GyW"
   },
   "outputs": [],
   "source": [
    "!export PATH=/home/ondrej.palkoci/anaconda3/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "biH7cGLmmzem",
    "outputId": "71c65cc2-c9cc-46e3-a804-45fe49d60424"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ondrej.palkoci/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from seaborn import heatmap\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "5dnQIHL1puVq",
    "outputId": "2c9e83a2-fa97-4ba8-8690-5c0d2d4082f6"
   },
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import rescale\n",
    "\n",
    "def read_images(path, output_sz=(224, 224), ending='.JPG'):\n",
    "    print('Reading from', path)\n",
    "    files = [file for file in os.listdir(path) if file.endswith(ending)]\n",
    "    image = imread(path+files[0])\n",
    "    images = np.zeros(shape=(len(files), output_sz[0], output_sz[1], image.shape[2]))\n",
    "    for i in range(len(files)):\n",
    "        image = imread(path+files[i])\n",
    "        # images[i,:,:,:] = rescale(image, 1/downsample, multichannel=True)\n",
    "        images[i,:,:,:] = cv2.resize(image, dsize=output_sz, interpolation=cv2.INTER_AREA)\n",
    "    print('Original resolution:', image.shape)\n",
    "    print('New resolution:', images[0].shape)\n",
    "    return images\n",
    "\n",
    "# zdrave = read_images(path='zdrave/')\n",
    "# esca = read_images(path='esca/')\n",
    "# suche = read_images(path='suche/')\n",
    "# zdrave_zber = read_images(path='zdrave_zber/')\n",
    "# esca_koniec = read_images(path='train_esca_zber/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d_gCy0oRbWzM",
    "outputId": "f434c386-96d7-4626-d71e-3e79d3a798aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread('keras_folders1/test/healthy/image_test1.png').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "WLFUpFcjr5UI",
    "outputId": "503f1a9b-44f6-48d9-fa53-7c8ac24cd800"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAE3VJREFUeJzt3X+UXGV9x/F32AVMYGtXXDEGC3KO\n/VpKa1vxFxIICCoKogalSoHT4JGqoPZIPWhbwHAQUFGsIMIx/G6tgAqJSqQhoGgAgaqUar8CCloT\nzLauNpg0/JD+ce+WyWZ/TDYzmXl23q9z9uzMvXdmv8/dO5/nmWfmzsx68sknkSSVZbtOFyBJ2nKG\ntyQVyPCWpAIZ3pJUIMNbkgrUvy3+yPDwuq5/S8vg4BxGRtZ3uoyO6OW2Q2+3v5fbDt3f/qGhgVkT\nrXPkXevv7+t0CR3Ty22H3m5/L7cdym6/4S1JBTK8JalAhrckFcjwlqQCGd6SVCDDW5IKZHhLUoEM\nb0kqkOEtSQXaJqfHb61FZ6/sdAktcckpB3W6BEkzhCNvSSqQ4S1JBTK8JalAhrckFcjwlqQCGd6S\nVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBVoyg+miojjgWMaFu0DvAK4EHgSuCcz39me8iRJ\n45ly5J2ZSzJzQWYuAE4DLgfOA96bma8Anh4Rh7a3TElSoy2dNjkVOAd4XmbeWS9bBhzc0qokSZNq\n+vO8I+LFwM+Ax4GRhlVrgbmT3XZwcA79/X3TKnAmGRoa6HQJE+rm2raFXm5/L7cdym3/lnwZw9uB\ny8ZZPmuqG46MrN+CPzNzDQ+v63QJ4xoaGuja2raFXm5/L7cdur/9k3UsWzJtsgBYBQwDuzQsnwes\nnk5hkqTpaSq8I+I5wCOZ+WhmPgb8R0TsV69+E7C8XQVKkjbX7LTJXKq57VHvAy6KiO2AOzJzRcsr\nkyRNqKnwzsy7gUMbrv8AmN+uoiRJk/MMS0kqkOEtSQUyvCWpQIa3JBXI8JakAhneklQgw1uSCmR4\nS1KBDG9JKpDhLUkFMrwlqUCGtyQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ4S1JBWrqa9Ai4mjg\nA8DjwKnAPcCVQB+wBjgmMze2q0hJ0qamHHlHxC7AacB+wGHAEcBi4ILMnA/cDyxqZ5GSpE01M21y\nMLAiM9dl5prMfAewAFhar19WbyNJ2kaamTbZA5gTEUuBQeB0YKeGaZK1wNzJ7mBwcA79/X1bUebM\nMDQ0sMW3Ofz917ehks5Ydu4RnS5hQtP538wUvdx2KLf9zYT3LGAX4I3A7sDN9bLG9ZMaGVk/reJm\nmuHhdZ0uoaO6tf1DQwNdW1u79XLbofvbP1nH0sy0yS+AVZn5eGY+AKwD1kXE7Hr9PGD1VlcpSWpa\nMyPvG4HLIuIcqmmTnYGvAwuBq+rfy9tWodSjFp29stMltMwlpxzU6RJmnClH3pn5c+Ba4HbgBuAk\nqnefHBcRtwLPAC5vZ5GSpE019T7vzLwIuGjM4kNaX44kqRmeYSlJBTK8JalAhrckFcjwlqQCGd6S\nVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9JKpDhLUkF\nMrwlqUBTfg1aRCwArgH+vV70b8BHgSuBPmANcExmbmxTjZKkMZodeX8jMxfUPycBi4ELMnM+cD+w\nqG0VSpI2M91pkwXA0vryMuDgllQjSWpKU98eD+wVEUuBZwAfBnZqmCZZC8xtR3GSpPE1E973UQX2\n1cCewM1jbjdrqjsYHJxDf3/ftAqcSYaGBjpdQkd1c/u7ubaZoJv3bzfXNpkpwzszfw58ob76QEQ8\nDLw4ImZn5gZgHrB6svsYGVm/1YXOBMPD6zpdQkd1a/uHhga6traZolv3b7f/7yfrWKac846IoyPi\n5Prys4FdgUuBhfUmC4HlW1+mJKlZzUybLAX+KSKOAHYA3gl8F7giIk4AHgIub1+JkqSxmpk2WQcc\nPs6qQ1pfjiSpGZ5hKUkFMrwlqUCGtyQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ4S1JBTK8JalA\nhrckFcjwlqQCGd6SVCDDW5IKZHhLUoEMb0kqULPfHi9J28yis1d2uoSWueSUg9pyv468JalAhrck\nFaipaZOImA3cC5wB3ARcCfQBa4BjMnNj2yqUJG2m2ZH33wG/rC8vBi7IzPnA/cCidhQmSZrYlOEd\nES8A9gK+Wi9aACytLy8DDm5LZZKkCTUzbXIucCJwXH19p4ZpkrXA3KnuYHBwDv39fdOrcAYZGhro\ndAkd1c3t7+baZoJe3r/tavuk4R0RxwK3ZeZPImK8TWY180dGRtZPo7SZZ3h4XadL6Khubf/Q0EDX\n1jZT9PL+3Zq2Txb8U428XwfsGRGHAbsBG4FHImJ2Zm4A5gGrp12ZJGlaJg3vzDxq9HJEnA48COwL\nLASuqn8vb195kqTxTOd93qcBx0XErcAzgMtbW5IkaSpNnx6fmac3XD2k9aVIkprlGZaSVCDDW5IK\nZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9JKpDhLUkFMrwlqUCG\ntyQVyPCWpAIZ3pJUIMNbkgo05degRcQc4DJgV+BpwBnA94ErgT5gDXBMZm5sX5mSpEbNjLwPB+7K\nzAOAtwCfABYDF2TmfOB+YFH7SpQkjTXlyDszv9Bw9bnAfwILgL+qly0DTgYubHVxkqTxNf3t8RGx\nCtgNOAxY0TBNshaYO9ltBwfn0N/fN+0iZ4qhoYFOl9BR3dz+bq5tJujl/duutjcd3pm5b0T8CXAV\nMKth1awJbvL/RkbWT6O0mWd4eF2nS+iobm3/0NBA19Y2U/Ty/t2atk8W/FPOeUfEiyLiuQCZ+T2q\nwF8XEbPrTeYBq6ddnSRpizXzguX+wPsBImJXYGdgBbCwXr8QWN6W6iRJ42pm2uSzwJKIuBWYDbwb\nuAu4IiJOAB4CLm9fiZKksZp5t8kG4G3jrDqk9eVIkprhGZaSVCDDW5IKZHhLUoEMb0kqkOEtSQUy\nvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9JKpDhLUkFMrwlqUCGtyQVyPCWpAIZ3pJUIMNb\nkgrUzHdYEhEfBebX258F3AlcCfQBa4BjMnNju4qUJG1qypF3RBwI7J2ZLwdeA5wHLAYuyMz5wP3A\norZWKUnaRDPTJt8E3lxf/hWwE7AAWFovWwYc3PLKJEkTaubb458AflNfPR74GvDqhmmStcDcye5j\ncHAO/f19W1PnjDA0NNDpEjqqm9vfzbXNBL28f9vV9qbmvAEi4giq8H4VcF/DqllT3XZkZP2WVzYD\nDQ+v63QJHdWt7R8aGuja2maKXt6/W9P2yYK/qXebRMSrgb8FDs3MXwOPRMTsevU8YPW0q5MkbbFm\nXrB8OvAx4LDM/GW9eAWwsL68EFjenvIkSeNpZtrkKOCZwNURMbrsOOBzEXEC8BBweXvKkySNp5kX\nLC8GLh5n1SGtL0eS1AzPsJSkAhneklQgw1uSCmR4S1KBDG9JKlDTZ1hK29qis1d2uoSWueSUgzpd\ngmYYR96SVCDDW5IKZHhLUoEMb0kqkOEtSQUyvCWpQIa3JBXI8JakAhneklQgw1uSCmR4S1KBDG9J\nKlBTH0wVEXsD1wOfzMzzI+K5wJVAH7AGOCYzN7avTElSo2a+PX4n4NPATQ2LFwMXZOZ84H5gUXvK\nkySNp5lpk43Aa4HVDcsWAEvry8uAg1tbliRpMs18e/zjwOMR0bh4p4ZpkrXA3DbUJkmaQCu+jGHW\nVBsMDs6hv7+vBX+qbENDA50uoaN6uf293Hbo7fa3q+3TDe9HImJ2Zm4A5rHplMpmRkbWT/PPzCzD\nw+s6XUJH9XL7e7nt0Nvt35q2Txb8032r4ApgYX15IbB8mvcjSZqGKUfeEfEi4FxgD+CxiDgSOBq4\nLCJOAB4CLm9nkZKkTTXzguXdVO8uGeuQllcjSWqKZ1hKUoEMb0kqkOEtSQUyvCWpQIa3JBXI8Jak\nAhneklQgw1uSCmR4S1KBDG9JKpDhLUkFMrwlqUCGtyQVyPCWpAIZ3pJUIMNbkgpkeEtSgQxvSSqQ\n4S1JBZryOywnEhGfBF4GPAm8NzPvbFlVkqRJTWvkHREHAM/PzJcDxwP/0NKqJEmTmu60ySuB6wAy\n84fAYET8TsuqkiRNataTTz65xTeKiIuBr2bm9fX1W4HjM/NHLa5PkjSOVr1gOatF9yNJasJ0w3s1\n8OyG688B1mx9OZKkZkw3vG8EjgSIiD8DVmfmupZVJUma1LTmvAEi4mxgf+C3wLsz8/utLEySNLFp\nh7ckqXM8w1KSCmR4S1KBDG+pFhG3RMTena6j1SJi54h4sNN1qLUM7x4XEZdFxGFbcftTIuLlraxJ\nGk83dEIR8WBE7NzJGkZN+4OpShERfcDFwJ7A9sCpwG7AicCjwPcz890R8afAZ6jePbMqM/8mIg4G\nzqi3GwHekpmPdqAZXSszz+50DY0i4veAq4AnqI7vFcBAZp5cP+juzcw9IuIQ4CP1dv+cmefVd/GW\niPgUsAvw+sz8aUScCcwH+oDzM/Pz27hZU4qIdwJH1VefT3XM7wc8DfhWw3b3AV8D1gJfAS4AHqM6\n7t8M/D3w3cy8ot7+R1QfQPdW4G31dtdl5rntb5UmM+PDm+qAW5OZx0fEM4GV9fLXZebPIuIvI2I2\n1YdrnZCZ90TEFRGxOzAIvC0zfxIRVwCvBpZti6K3dacTEdsDNwBnAvcBlwA71Pd7PNWnR14OPAC8\nkOoB/vaIuAy4tr7tJvVm5srx6mvB7pnMkcC/ZOYZ9TkIrwIGxrR1Vl3TvsAvgesj4qJ69drMfGVE\nnAW8KSLuBnbPzP0jYkfgXyPiuszc0OZ2bJHMvBC4MCJ2ozpGH6PqqP46Io6iCl+o/jc3ZObyugM7\nKTO/GxGLgaOBLwHvAa6IiD8GHgSeTrVf96vv49sRcU1m/rTV7eiWTqjOhBvqq9sD+2TmjvX1D0XE\nfOBx4I3AOsY/9m8B7gXIzBOnvVMm0AvTJvsCb6h35LXAbOCLwJcj4n3A1+oHYmTmPQCZeWxmPgQM\nA5+LiG8AB1KNxraV0U7nQOANwHnAycDCzNwPuGtMp/MKYNcxnc4BwP9QdTpT+SRwdWbeDCwGlmTm\nAqqQO73e5kXAh4AXA6+NiN+dol4mqK+dbgSOjYhzgR2Bh8fZZgj438wczswnMvOwhjAeDYifU4XW\nvsDL6uPn61SPmbntbMB0RcR2VB3se6jOel5Vr7plzKbfqX//AvhIfXy/ler4/jbwwojYATiC6jHz\nEqogvbn+GQD2aEcbMvPC+rj7C6pgHu2E5gPfa9h0tBM6E3gWVSd0YF3/aCd0OMAEndD+wML6mdp4\ndWzIzAV1LauADzasvqeu527gGCY+9qlrb3lwQ2+MvB8Fzhz7VDciLqX6R66MiNGTjca6hGqE/sOI\nOL/9pW5iX2B+RIyOdmZTTQd8OSKuAj6fmRsiYpNOByAinkfV6fRTjQZWbn73mzgO2LHhINuHpw7W\nm6lG/QD3Z+bD9d9YTfVgmLDeOgA2q6+dMvPeiHgh1Yj7LODShtXb17+fYOKBy+MNl2dRHT9LMvOs\nVtfaBh8Evp2Zt0bEn/PUMT22raPPwj4FnFOPwk8Gds7M30bEzcABwOuoAnA/qg+iO6H9TdisEzoK\n+Ea96pYxmzZ2QudExByqTusfqUJ8ySSdEDzVCU34DKJ+Frs38IGGxaO3/w5VJ9DH+Md+Y40t1wvh\nfQfVP+/zEfEs4H1UUwCnZ+YnImIvYHfgBxHx0sy8IyKWAB+nCqef1iPMA4F7tmHd27LT2Q7YMyKe\nn5n3Ue2f0Q8bG506gU2DDTb9QLKJ6h2vvrapQ+vHmXldRPwXcCFP/d/2A8jM/46IvoiYR/U5Pcuo\nRnrjuQP4eEScQ7UvPpaZJ7W1EdMQES+l6rAOqhclVSf8RapjdzzPBB6op4NeC9xeL/8ScCzwm8wc\nrqeORsNxA9XI8pQ2Th11RSdUT7N+HHhNZjaezTj28kTHfmONLdcL0yZXA49ExCqqB+mtVHNUt0XE\nTVQ7/3vAe4FzI+JbwEj9OeUXUPXgFwMfBT4YEdvqKfNop0NEPCsiPlK/cLYmMz8B3EZDp1NvtyQi\n/oDNO50dxv0LT7mUapSzpJ4PvpOnHvAHAHdNp956+Xj1tdOPgPMjYiVwGlUoRz3t8QKeCoJ3UY3G\nVgE3ZeavxruzzFxFNdK6Dfgm1VPlbrSYKoxvqtv6+1TTPTcBwaaBM+rTVJ/Lf019+bj6WctK4FCq\n4Kee2z6Pqv23Aw+3K7gbOqEP14tGOyFovhMaPd436YSo/ncHRsSciJgVEZ+qpx4nsgT40OizzQbz\n698vA37IxMd+W3l6fJeqpzw+C+xF9bTsdKoXCo8Efg38GDgB+EOq0SXA7fW7KhYDr6cKsq/Wt903\nMzf75MfRFxwz8ysR8Vmqg/EaqgN3R6qRw/FUUw7XZuY+9e3uqms5nSoEl4+tNzNviIg/Glvf1u8d\nzVQR8XWqF+aH60X3Uh3jv6V6PeLYzHxeVG8Z3DszH4mId1ANvh6gGoicTxXiP6D6tNNTM/Mz9f2/\nC1hENXV23UTTYVG9/XUF1UBm1NvrZZdQTZcAvAlYz/jH/i3AiZl571bskgkZ3pJUoF6Y8+559Ysn\nN46zKrfVi1BSN4qIl1BNiY71hfrtl13LkbckFagXXrCUpBnH8JakAhneklQgw1uSCvR/P2WW8dkK\ncosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2abce12a90>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(0)\n",
    "plt.bar(['zdrave', 'esca', 'suche', 'zdrave_zber', 'esca_koniec'],\\\n",
    "        [zdrave.shape[0], esca.shape[0], suche.shape[0], zdrave_zber.shape[0], esca_koniec.shape[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mE5smPS3Hj0I"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "main_folder = 'keras_folders2'\n",
    "\n",
    "# !rm -r main_folder\n",
    "os.mkdir(main_folder)\n",
    "os.mkdir(main_folder+'/train')\n",
    "os.mkdir(main_folder+'/test')\n",
    "os.mkdir(main_folder+'/train/healthy')\n",
    "os.mkdir(main_folder+'/train/esca')\n",
    "os.mkdir(main_folder+'/train/dry')\n",
    "os.mkdir(main_folder+'/train/esca_koniec')\n",
    "os.mkdir(main_folder+'/test/healthy')\n",
    "os.mkdir(main_folder+'/test/esca')\n",
    "os.mkdir(main_folder+'/test/dry')\n",
    "os.mkdir(main_folder+'/test/esca_koniec')\n",
    "\n",
    "zdrave_merged = np.concatenate((zdrave, zdrave_zber), axis=0)\n",
    "# esca_merged = np.concatenate((esca, esca_koniec), axis=0)\n",
    "\n",
    "def create_keras_folders(images, label, train_ratio=0.8):\n",
    "    images_rnd = images[np.random.permutation(len(images))]\n",
    "\n",
    "    train_set = images_rnd[:int(0.8*len(images_rnd))]\n",
    "    test_set = images_rnd[int(0.8*len(images_rnd)):]\n",
    "\n",
    "    for i in range(len(train_set)):\n",
    "        print(main_folder+'/train/'+str(label)+'/image_train'+str(i)+'.png')\n",
    "        cv2.imwrite(main_folder+'/train/'+str(label)+'/image_train'+str(i)+'.png', train_set[i])\n",
    "        \n",
    "\n",
    "    for i in range(len(test_set)):\n",
    "        print(main_folder+'/test/'+str(label)+'/image_test'+str(i)+'.png')\n",
    "        cv2.imwrite(main_folder+'/test/'+str(label)+'/image_test'+str(i)+'.png', test_set[i])\n",
    "\n",
    "create_keras_folders(zdrave_merged, label='healthy')\n",
    "create_keras_folders(esca, label='esca')\n",
    "create_keras_folders(suche, label='dry')\n",
    "create_keras_folders(esca_koniec, label='esca_koniec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "VMKdvyZmtAIq",
    "outputId": "d4365080-277b-45bb-c136-2c65c499378e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 45,718,595\n",
      "Trainable params: 45,718,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Dense\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# base_model = MobileNet(include_top=False, alpha=1.0, dropout=1e-3, weights='imagenet', input_shape=(224,224,3))\n",
    "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "# base_model = NASNetMobile(include_top=False, weights=None, input_shape=(224,224,3))\n",
    "# base_model = NASNetMobile(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "# base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "# Add the convolutional base model\n",
    "model.add(base_model)\n",
    " \n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "0ypFjGszoT5y",
    "outputId": "da37a149-f247-40f5-8800-51cea162546a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7fd8a9a9c320> False\n",
      "<keras.layers.core.Flatten object at 0x7fd8a9d16e10> False\n",
      "<keras.layers.core.Dense object at 0x7fd8a9a86e80> True\n",
      "<keras.layers.core.Dense object at 0x7fd8a99686a0> True\n"
     ]
    }
   ],
   "source": [
    "# Freeze the layers except the last 2 layers\n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dQkEoFpTY8OM",
    "outputId": "89841d3c-7c18-42d2-f5c5-08db92133c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 3 classes.\n",
      "Found 53 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "# train_batchsize = 100\n",
    "# val_batchsize = 10\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('keras_folders3/keras_folders3/train',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory('keras_folders3/keras_folders3/test',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1527
    },
    "colab_type": "code",
    "id": "B6uL-SKcF98D",
    "outputId": "8f6989c1-5063-4786-8889-a8eda36f4135",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/6 [=================================] - 22s 3s/step - loss: 5.0492 - acc: 0.5733 - val_loss: 1.9053 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.90527, saving model to model-001.h5\n",
      "Epoch 2/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 1.8912 - acc: 0.8316 - val_loss: 3.4940 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.90527\n",
      "Epoch 3/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 1.0849 - acc: 0.9094 - val_loss: 1.5828 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.90527 to 1.58283, saving model to model-003.h5\n",
      "Epoch 4/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 1.1822 - acc: 0.9267 - val_loss: 2.0227 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58283\n",
      "Epoch 5/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7305 - acc: 0.9547 - val_loss: 1.9431 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58283\n",
      "Epoch 6/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.9354 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58283\n",
      "Epoch 7/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.9246 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.58283\n",
      "Epoch 8/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.9097 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.58283\n",
      "Epoch 9/100\n",
      "7/6 [=================================] - 1s 126ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.9039 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.58283\n",
      "Epoch 10/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.8980 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.58283\n",
      "Epoch 11/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.8919 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.58283\n",
      "Epoch 12/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8846 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.58283\n",
      "Epoch 13/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8755 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.58283\n",
      "Epoch 14/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8687 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.58283\n",
      "Epoch 15/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8611 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.58283\n",
      "Epoch 16/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8549 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.58283\n",
      "Epoch 17/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.8437 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.58283\n",
      "Epoch 18/100\n",
      "7/6 [=================================] - 1s 126ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.8337 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.58283\n",
      "Epoch 19/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8215 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.58283\n",
      "Epoch 20/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8141 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.58283\n",
      "Epoch 21/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.8088 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.58283\n",
      "Epoch 22/100\n",
      "7/6 [=================================] - 1s 126ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7927 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.58283\n",
      "Epoch 23/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7859 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.58283\n",
      "Epoch 24/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7773 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.58283\n",
      "Epoch 25/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7707 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.58283\n",
      "Epoch 26/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7633 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.58283\n",
      "Epoch 27/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7597 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.58283\n",
      "Epoch 28/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7565 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.58283\n",
      "Epoch 29/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7436 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.58283\n",
      "Epoch 30/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7318 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.58283\n",
      "Epoch 31/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7224 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.58283\n",
      "Epoch 32/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7141 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.58283\n",
      "Epoch 33/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 1.1081 - acc: 0.9313 - val_loss: 1.7094 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.58283\n",
      "Epoch 34/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.6995 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.58283\n",
      "Epoch 35/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7061 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.58283\n",
      "Epoch 36/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.58283\n",
      "Epoch 37/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.58283\n",
      "Epoch 38/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.58283\n",
      "Epoch 39/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.58283\n",
      "Epoch 40/100\n",
      "7/6 [=================================] - 1s 121ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.58283\n",
      "Epoch 41/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.58283\n",
      "Epoch 42/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.58283\n",
      "Epoch 43/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.58283\n",
      "Epoch 44/100\n",
      "7/6 [=================================] - 1s 121ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_loss did not improve from 1.58283\n",
      "Epoch 45/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.58283\n",
      "Epoch 46/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.58283\n",
      "Epoch 47/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.58283\n",
      "Epoch 48/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.58283\n",
      "Epoch 49/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.58283\n",
      "Epoch 50/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.58283\n",
      "Epoch 51/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.58283\n",
      "Epoch 52/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.58283\n",
      "Epoch 53/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.58283\n",
      "Epoch 54/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.58283\n",
      "Epoch 55/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.58283\n",
      "Epoch 56/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.58283\n",
      "Epoch 57/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.58283\n",
      "Epoch 58/100\n",
      "7/6 [=================================] - 1s 126ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.58283\n",
      "Epoch 59/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.58283\n",
      "Epoch 60/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.58283\n",
      "Epoch 61/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.58283\n",
      "Epoch 62/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.58283\n",
      "Epoch 63/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.58283\n",
      "Epoch 64/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.58283\n",
      "Epoch 65/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.58283\n",
      "Epoch 66/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.58283\n",
      "Epoch 67/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.58283\n",
      "Epoch 68/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.58283\n",
      "Epoch 69/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.58283\n",
      "Epoch 70/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.58283\n",
      "Epoch 71/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.58283\n",
      "Epoch 72/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.58283\n",
      "Epoch 73/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.58283\n",
      "Epoch 74/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.58283\n",
      "Epoch 75/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.58283\n",
      "Epoch 76/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.58283\n",
      "Epoch 77/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.58283\n",
      "Epoch 78/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.58283\n",
      "Epoch 79/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.58283\n",
      "Epoch 80/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.58283\n",
      "Epoch 81/100\n",
      "7/6 [=================================] - 1s 121ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.58283\n",
      "Epoch 82/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.58283\n",
      "Epoch 83/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.58283\n",
      "Epoch 84/100\n",
      "7/6 [=================================] - 1s 121ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.58283\n",
      "Epoch 85/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.58283\n",
      "Epoch 86/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.58283\n",
      "Epoch 87/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.58283\n",
      "Epoch 88/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_loss did not improve from 1.58283\n",
      "Epoch 89/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.58283\n",
      "Epoch 90/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.58283\n",
      "Epoch 91/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.58283\n",
      "Epoch 92/100\n",
      "7/6 [=================================] - 1s 125ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.58283\n",
      "Epoch 93/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.58283\n",
      "Epoch 94/100\n",
      "7/6 [=================================] - 1s 122ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.58283\n",
      "Epoch 95/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.58283\n",
      "Epoch 96/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.58283\n",
      "Epoch 97/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.58283\n",
      "Epoch 98/100\n",
      "7/6 [=================================] - 1s 123ms/step - loss: 0.7304 - acc: 0.9547 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.58283\n",
      "Epoch 99/100\n",
      "7/6 [=================================] - 1s 124ms/step - loss: 1.1081 - acc: 0.9313 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.58283\n",
      "Epoch 100/100\n",
      "7/6 [=================================] - 1s 121ms/step - loss: 0.9192 - acc: 0.9430 - val_loss: 1.7048 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.58283\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=5e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "JT0KY3PLnD2_",
    "outputId": "984625a4-c5bd-40a9-874b-2e3156f3ddf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7fd8a9a9c320> False\n",
      "<keras.layers.core.Flatten object at 0x7fd8a9d16e10> False\n",
      "<keras.layers.core.Dense object at 0x7fd8a9a86e80> True\n",
      "<keras.layers.core.Dense object at 0x7fd8a99686a0> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "I_He3SxDrhB8",
    "outputId": "1b640d2b-d60a-43d9-e305-55aaa95bb804"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-5699334eeee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# images = [file for file in os.listdir('keras_folders1/val')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'keras_folders1/val/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_images' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# images = [file for file in os.listdir('keras_folders1/val')]\n",
    "val_images = read_images(path='keras_folders1/val/', ending='png')\n",
    "\n",
    "model.predict_classes(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FXlMJKR7u1bX"
   },
   "outputs": [],
   "source": [
    "# model.save('mobile_net_2_classes.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VLrsRi9Q1rcz"
   },
   "outputs": [],
   "source": [
    "!cp -r keras_folders2 keras_folders3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"suche.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"suche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ondrej.palkoci/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:304: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model4 = load_model('VGG19_79_4_classes.h5')\n",
    "# model.predict_classes(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ondrej.palkoci/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:304: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model3 = load_model('VGG19_83_3classes.h5')\n",
    "# model.predict_classes(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from suche/suche/\n",
      "Original resolution: (224, 224, 3)\n",
      "New resolution: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "suche = read_images(path='suche/suche/', ending='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from healthy/healthy/\n",
      "Original resolution: (224, 224, 3)\n",
      "New resolution: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "healthy = read_images(path='healthy/healthy/', ending='PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XE1_qA_kLcrZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "esca_competition.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
